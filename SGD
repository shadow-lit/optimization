def torch_(x1, x2, y, lr = 0.0001):
	w1 = Variable(torch.tensor(1).float(), requires_grad = True)
	w2 = Variable(torch.tensor(1).float(), requires_grad = True)
	optim = torch.optim.SGD([w1, w2], lr=lr) #构建优化器
	l = []
	for i in range(x1.shape[0]):
		y_ = w1 * x1[i]**2 + w2*x2[i]**2
		loss = (y[i] - y_)**2 #损失函数
		optim.zero_grad()     #梯度清零
		loss.backward()       #梯度计算
		optim.step()          #参数更新
		s = sum(w1*x1**2 + w2 * x2**2 - y)**2/x1.shape[0]
		l.append(s.item())
	plt.plot(range(len(l)), l)
	plt.show()
	print(w1)
	print(w2)
